<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>What-The-Text</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="introduction.html">Introduction</a></li>
							<li><a href="data.html">Data</a></li>
							<li><a href="cleaning.html">Cleaning</a></li>
                            <li><a href="clustering.html">Clustering</a></li>
                            <li><a href="arm.html">ARM</a></li>
                            <li><a href="lda.html">LDA</a></li>
                            <li><a href="naivebayes.html">Naive Bayes</a></li>
                            <li><a href="dt.html">Decision Tree</a></li>
                            <li><a href="svm.html">Support Vector Machines</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Support Vector Machines</h1>
							<!-- <span class="image main"><img src="images/pic13.jpg" alt="" /></span> -->
                            <br>
                            <h3>Overview</h3>
							<p>Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression tasks.<br>
                                It is particularly well-suited for classification tasks and has been widely used in various domains, including text classification, image recognition, and bioinformatics.<br>
                                At its core, SVM aims to find the optimal hyperplane that separates data points of different classes with the maximum margin. 
                            </p>

                            <p>
                                SVM can handle nonlinear relationships between features and class labels by mapping the input data into a higher-dimensional feature space using kernel functions.<br>
                                Common kernel functions include linear, polynomial, and radial basis function (RBF). The kernel trick allows SVM to find nonlinear decision boundaries in the original feature space without explicitly computing the transformed feature space.<br>
                            </p>

                            <p>
                                SVMs work well in high-dimensional spaces, making them suitable for text classification tasks where each word or term represents a feature. Text data is typically high-dimensional due to the large number of unique words or terms, and SVMs can effectively separate data points in such spaces.<br>
                                SVMs can efficiently handle nonlinear relationships between features and class labels using different kernel functions (e.g., linear, polynomial, radial basis function). This flexibility allows SVMs to capture complex patterns and decision boundaries in text data, leading to accurate classification.<br>
                                SVMs typically rely only on a subset of training examples (support vectors) to define the decision boundary. This property makes SVMs memory-efficient, especially in text classification tasks with large datasets, where only a small fraction of training examples may be relevant for defining the decision boundary.
                            </p>
                            
                            <h3>Data Prep</h3>
                            <p>
                                To split data into training and testing sets without any overlap, you can use the train_test_split function from the scikit-learn library in Python. It internally handles choosing datapoints without replacement, making sure that there are no common data points between training and testing set.<br>
                                Naive Bayes in python requires all the features to be in numeric form. Here is the sample input dataset:
                            </p>

                            <img src="images/numeric_data.png"><br><br>
                            <p><a href="https://github.com/vatshivam/what_the_text/blob/main/numeric_data.csv">Link</a> to the data</p>

                            <p>Applying train test split divide the data and labels into training and testing sets.</p>
                            
                            <h4>X_train</h4>
                            <img src="images/X_train.png"><br><br>

                            <h4>X_test</h4>
                            <img src="images/X_test.png"><br><br>

                            <h4>Y_train and Y_test</h4>
                            <img src="images/y_train_test.png"><br><br>

                            <h3>Code</h3>
                            <p>Here is the <a href="https://github.com/vatshivam/what_the_text/blob/main/SVM.ipynb">code</a> to implement SVM classifier</p>
                            
                            <h3>Results</h3>

                            <p>Let's take a look at the classification metrics for different kernels, when used with the text dataset.</p>
                            
                            <p>RBF</p>
                            <img src="images/rbf_cm.png"><br><br>
                            <img src="images/rbf_cr.png"><br><br>

                            <p>Polynomial</p>
                            <img src="images/poly_cm.png"><br><br>
                            <img src="images/poly_cr.png"><br><br>

                            <p>Sigmoid</p>
                            <img src="images/sigmoid_cm.png"><br><br>
                            <img src="images/sigmoid_cr.png"><br><br>

                            <h3>Conclusion</h3>
                            <p>
                                RBF outperformed the rest of the two kernels for this dataset. In addition to that, RBF kernel was able to acheive a higher accuracy for minority class, as compared to the other kernels.<br>
                                In addition to that, SVM performed better than naive bayes and decision trees overall.  Since the dataset has well-separated classes, SVMs outperformed Decision Trees and Naive Bayes, which do not explicitly optimize for margin maximization.<br>
                                SVMs make fewer assumptions about the underlying data distribution compared to Naive Bayes, which assumes feature independence, and Decision Trees, which may suffer from bias towards dominant features or classes.
                            </p>
						</div>
					</div>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<section>
								<h2>Get in touch</h2>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<input type="text" name="name" id="name" placeholder="Name" />
										</div>
										<div class="field half">
											<input type="email" name="email" id="email" placeholder="Email" />
										</div>
										<div class="field">
											<textarea name="message" id="message" placeholder="Message"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send" class="primary" /></li>
									</ul>
								</form>
							</section>
							<section>
								<h2>Follow</h2>
								<ul class="icons">
									<li><a href="#" class="icon brands style2 fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon brands style2 fa-facebook-f"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon brands style2 fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon brands style2 fa-dribbble"><span class="label">Dribbble</span></a></li>
									<li><a href="#" class="icon brands style2 fa-github"><span class="label">GitHub</span></a></li>
									<li><a href="#" class="icon brands style2 fa-500px"><span class="label">500px</span></a></li>
									<li><a href="#" class="icon solid style2 fa-phone"><span class="label">Phone</span></a></li>
									<li><a href="#" class="icon solid style2 fa-envelope"><span class="label">Email</span></a></li>
								</ul>
							</section>
							<ul class="copyright">
								<li>&copy; Untitled. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>